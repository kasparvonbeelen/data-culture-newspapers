{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasparvonbeelen/data-culture-newspapers/blob/main/2_Poking_LLMs_with_HF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-2ldxb0iUxG"
      },
      "source": [
        "# Using open-source LLMs for analysing humanities data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_e5BL9Ti3JG"
      },
      "source": [
        "In this notebook, we explore applications of generative AI for processing and analysing historical newspapers.\n",
        "\n",
        "Instead of investigating how the model works, we focus on what we can do with the outputs.\n",
        "\n",
        "Major hurdles to working with LLMs are cost and/or infrastructure. Opposed to GPT-2 or BERT, running LLMs can be difficult, and using commercial APIs can be expensive.\n",
        "\n",
        "## Why Open-source?\n",
        "\n",
        "- **Privacy:**: You might not want to share your data (and ideas) with companies such as OpenAI;\n",
        "- **Cost:** Making abstraction of the caveat above, using open-source models might reduce costs if you want to apply for example a prompt to 10k newspaper articles;\n",
        "- **Transparency:** Be mindful that there are different gradations of openness and transparency. Even when you can access the model weights, you might remain in the dark about training data and other factors);\n",
        "- **Flexibility:** Even though some providers allow you to train or fine-tune closed models on your data (ties in with privacy), open-source models still give you more freedom and wiggle room to build new models and applications.\n",
        "\n",
        "## Goals of this Session\n",
        "\n",
        "This notebook covers a few practical and theoretical aspects of working with LLMs in the context of humanities research. The goal is to start a discussion on:\n",
        " - Where to find and how to deploy open-source LLMs?\n",
        " - What tasks would make sense? Which models work well for a selected task?\n",
        " - How to evaluate outcomes and performance? How large should the language model be?\n",
        "\n",
        "We want to keep things simple!\n",
        "\n",
        "We will be playing with Llama-3 and get a feeling of how this changes the way we process and interrogate data.\n",
        "\n",
        "\n",
        "## Technical note\n",
        "\n",
        "We will be relying on the Hugging Face `InferenceClient` for accessing LLMs. These are freely accessible, but rate limits apply! If you would want to deploy a 'local' version (we're still on Colab, but the code should also work on your computer), uncomment the code below (where indicated) and make sure you are using a [GPU](https://cloud.google.com/gpu). To select a GPU on Colab Go to **`Runtime`** and select **`Change runtime type`**, then select `T4 GPU` (or any other GPU available).\n",
        "\n",
        "\n",
        "\n",
        "This notebook is inspired by: https://huggingface.co/learn/cookbook/structured_generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxa9ES0zX9ic"
      },
      "outputs": [],
      "source": [
        "# install the transformer and other libraries\n",
        "!pip install -q -U \"transformers==4.40.0\" pydantic accelerate outlines datasets bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXUryNZSXUd8"
      },
      "source": [
        "## The Hugging Face Hub\n",
        "\n",
        "In the examples below, we will experiment with `Llama-3-8B-Instruct`, a recent series of open-source LLMs created by Meta. To use Llama3 you need to:\n",
        "\n",
        "- Make an account on Hugging Face https://huggingface.co/\n",
        "- Go to the Llama-3-8B and sign the terms of use you should get a reply swiftly https://huggingface.co/meta-llama/Meta-Llama-3-8B\n",
        "- Create a user access token with at least read access: https://huggingface.co/docs/hub/en/security-tokens\n",
        "- Run the code cell below to log into the Hugging Face hub. Copy-paste the access token.\n",
        "- Reply `n` to the question 'Add token as git credential? (Y/n)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIuiPmuRV9aU",
        "outputId": "8ebe63be-e8d0-4163-8374-c117a5e4418b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpNX4yD1ch09"
      },
      "source": [
        "## Preparing model and data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtfaU-z2cLRC"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IivyFPPNQ0t-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # disable warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27FpdOCLasrJ"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from huggingface_hub import InferenceClient\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "pd.set_option(\"display.max_colwidth\", 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtl7poXAcMdJ"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RiZovNJXdlf"
      },
      "outputs": [],
      "source": [
        "# choose a LLMs model\n",
        "repo_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "# instantiate the inference client\n",
        "llm_client = InferenceClient(model=repo_id, timeout=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc9ROzqBjxan"
      },
      "outputs": [],
      "source": [
        "# # use this cell if you can access an A100 or L4 GPU\n",
        "# # define the model, we use the instruct variant\n",
        "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "# device = 'cuda' # make sure you use a GPU\n",
        "\n",
        "# # instantiate a text generation pipeline\n",
        "# pipeline = transformers.pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=checkpoint,\n",
        "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "#     device=\"cuda\",\n",
        "# )\n",
        "\n",
        "# # some fluff to improve the generation\n",
        "# terminators = [\n",
        "#     pipeline.tokenizer.eos_token_id,\n",
        "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use this cell if you can only access a T4 GPU\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "# # define the model, we use the instruct variant\n",
        "# checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "# device = 'cuda' # make sure you use a GPU if available\n",
        "\n",
        "# bnb_confic = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
        "# )\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# #tokenizer.pad_token = tokenizer.eos_token\n",
        "# model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "#                                              quantization_config=bnb_confic,\n",
        "#                                              device_map='auto')\n",
        "\n",
        "# pipeline = transformers.pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer= tokenizer,\n",
        "# )\n",
        "\n",
        "\n",
        "# # some fluff to improve the generation\n",
        "# terminators = [\n",
        "#     pipeline.tokenizer.eos_token_id,\n",
        "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "# ]"
      ],
      "metadata": {
        "id": "KN-l5VRih9Zm",
        "outputId": "fe9b29aa-1c73-4a24-bfbd-a54b05220746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "9a2f073bffe24c87abb9d81547b43311",
            "b2fb19d6b55c42a893b698ce22c02544",
            "ff43f1349df542bc9dbe21a98d32a809",
            "2e5dbb5d6c5d45afba265047753b9e20",
            "0e050d898f1643ca8a5c074a554286b4",
            "56faa1ef2ea6445a8fdf1614e75e1c08",
            "1451f4284e85462390c14e6057014c95",
            "6301aad1e0c046cba777e8eba409d55a",
            "28b8de963d02438ca4a9ce3ca7ae7f04",
            "03284201464b44d7b5d200035c3404c2",
            "4010561ef6e94f0caf25aa8166a49b06"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a2f073bffe24c87abb9d81547b43311"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk732HeUcOvO"
      },
      "source": [
        "### Download data\n",
        "\n",
        "We will be experimenting with a small set of 10k British newspaper articles provided by the [\"Heritage Made Digital\"](https://blogs.bl.uk/thenewsroom/2019/01/heritage-made-digital-the-newspapers.html) project. Data was kindly prepared and provided by my colleague [Nilo Pedrazzini](https://www.linkedin.com/in/nilopedrazzini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj-797e0Z9zr",
        "outputId": "24176773-3c02-4715-e74e-629d3737d270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_lwm_hmd_mt90 100%[===================>]  37.90M  70.2MB/s    in 0.5s    \n",
            "Archive:  sample_lwm_hmd_mt90_10000.csv.zip\n",
            "  inflating: sample_lwm_hmd_mt90_10000.csv  \n",
            "  inflating: __MACOSX/._sample_lwm_hmd_mt90_10000.csv  \n"
          ]
        }
      ],
      "source": [
        "# download a sample of 10.000 newspaper articles\n",
        "!wget -q --show-progress https://github.com/kasparvonbeelen/lancaster-newspaper-workshop/raw/wc/data/sample_lwm_hmd_mt90_10000.csv.zip\n",
        "# unzip the downloaded sample\n",
        "!unzip -o sample_lwm_hmd_mt90_10000.csv.zip\n",
        "!rm -r __MACOSX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP6EV9WhZXUR",
        "outputId": "12e0aea3-d826-497a-fe7f-336fd8e6f5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    NLP  issue  art_num       title  \\\n",
              "0  2194   1026  art0021    The Sun.   \n",
              "1  2645    925  art0004  The Press.   \n",
              "2  2194    323  art0006    The Sun.   \n",
              "\n",
              "                                         collection   full_date  year  month  \\\n",
              "0  British Library Heritage Made Digital Newspapers  1846-10-26  1846     10   \n",
              "1  British Library Heritage Made Digital Newspapers  1858-09-25  1858      9   \n",
              "2  British Library Heritage Made Digital Newspapers  1840-03-23  1840      3   \n",
              "\n",
              "   day         location  word_count  ocrquality  \\\n",
              "0   26  London, England         539      0.9705   \n",
              "1   25  London, England        2263      0.9663   \n",
              "2   23  London, England         795      0.9351   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  POOR T,i,ENIPAT A 1„k CT  The Poor Law Coirdnissioti(rs have issued a ei; cular, dated the 20th ...   \n",
              "1  THE PRESS, SEPTEMBER 25, 1858.  in managing their own business and dealing with matters of local...   \n",
              "2  PUBLICATIONS.  This day is published, in post Bvo., with Woodcuts and Twelve coloured Plates, pr...   \n",
              "\n",
              "   decade  \n",
              "0    1840  \n",
              "1    1850  \n",
              "2    1840  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ad440ad-7c5c-43dc-9577-ffb9fb616520\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NLP</th>\n",
              "      <th>issue</th>\n",
              "      <th>art_num</th>\n",
              "      <th>title</th>\n",
              "      <th>collection</th>\n",
              "      <th>full_date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>location</th>\n",
              "      <th>word_count</th>\n",
              "      <th>ocrquality</th>\n",
              "      <th>text</th>\n",
              "      <th>decade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2194</td>\n",
              "      <td>1026</td>\n",
              "      <td>art0021</td>\n",
              "      <td>The Sun.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1846-10-26</td>\n",
              "      <td>1846</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>London, England</td>\n",
              "      <td>539</td>\n",
              "      <td>0.9705</td>\n",
              "      <td>POOR T,i,ENIPAT A 1„k CT  The Poor Law Coirdnissioti(rs have issued a ei; cular, dated the 20th ...</td>\n",
              "      <td>1840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2645</td>\n",
              "      <td>925</td>\n",
              "      <td>art0004</td>\n",
              "      <td>The Press.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1858-09-25</td>\n",
              "      <td>1858</td>\n",
              "      <td>9</td>\n",
              "      <td>25</td>\n",
              "      <td>London, England</td>\n",
              "      <td>2263</td>\n",
              "      <td>0.9663</td>\n",
              "      <td>THE PRESS, SEPTEMBER 25, 1858.  in managing their own business and dealing with matters of local...</td>\n",
              "      <td>1850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2194</td>\n",
              "      <td>323</td>\n",
              "      <td>art0006</td>\n",
              "      <td>The Sun.</td>\n",
              "      <td>British Library Heritage Made Digital Newspapers</td>\n",
              "      <td>1840-03-23</td>\n",
              "      <td>1840</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>London, England</td>\n",
              "      <td>795</td>\n",
              "      <td>0.9351</td>\n",
              "      <td>PUBLICATIONS.  This day is published, in post Bvo., with Woodcuts and Twelve coloured Plates, pr...</td>\n",
              "      <td>1840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ad440ad-7c5c-43dc-9577-ffb9fb616520')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ad440ad-7c5c-43dc-9577-ffb9fb616520 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ad440ad-7c5c-43dc-9577-ffb9fb616520');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75225f3d-2ebe-4044-957c-74efa3cd9fd1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75225f3d-2ebe-4044-957c-74efa3cd9fd1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75225f3d-2ebe-4044-957c-74efa3cd9fd1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"NLP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 410,\n        \"min\": 2083,\n        \"max\": 3548,\n        \"num_unique_values\": 107,\n        \"samples\": [\n          2979,\n          2090,\n          2089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"issue\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 343,\n        \"min\": 101,\n        \"max\": 1231,\n        \"num_unique_values\": 366,\n        \"samples\": [\n          225,\n          1201,\n          1130\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"art_num\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 309,\n        \"samples\": [\n          \"art0330\",\n          \"art0107\",\n          \"art0031\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 106,\n        \"samples\": [\n          \"The Ripon Observer.\",\n          \"The Daily Times.\",\n          \"The Liverpool Standard, and General Advertiser.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"collection\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"British Library Living with Machines Project\",\n          \"British Library Heritage Made Digital Newspapers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 7316,\n        \"samples\": [\n          \"1842-02-15\",\n          \"1847-04-09\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 1801,\n        \"max\": 1920,\n        \"num_unique_values\": 119,\n        \"samples\": [\n          1852,\n          1884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          7,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          10,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 53,\n        \"samples\": [\n          \"Swansea, West Glamorgan, Wales\",\n          \"Warrington, Cheshire, England\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1689,\n        \"min\": 501,\n        \"max\": 24563,\n        \"num_unique_values\": 3159,\n        \"samples\": [\n          1675,\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ocrquality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023763277723342704,\n        \"min\": 0.9001,\n        \"max\": 1.0,\n        \"num_unique_values\": 944,\n        \"samples\": [\n          0.9238,\n          0.9595\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Jartign anb Colonial fnttlligence.  FRANC  - -The Monitenr of Tuesday last publishes the following in its non-qificica columns :\\u2014\\\"At Chalons-euratene on Saturday night, about 9 o'clock, some 40 individnala suddenly attacked a small poet of infantry, which they took by surprise. They then took the direction of the railway station, shouting 'Vice la Republiac \\\"The Republic is proclaimed in Paris I \\\" The Ilepnllo is everywehre I\\\" Citizens of Chilons, to arms I The stationmaster, an old soldier, assembled the men employed at the railway station, and drove back the rioters. From the railway station the mob proceeded to the bridge over the Saone, the head of which they occupied, to prevent an alarm being sent to the barracks. The officers of the garrison, who had hurried to the Sous-Prefecture to seeertain what the tumult wee about, cleared the bridge sword in hand. The troops socthgturned out, and the mob soon ditP\\u2022rowl- Before ht 15 of the more conspicuous ringleaders were in Itiaimpouibletodisguiaethefactthat the trade of FT&ncelznotatpreeentinuheslthy ietateucouldbe wished. The unfavourable influences which act on commercial affairs IWO of two kinds\\u2014the one political, the other financial. The consequences which have resulted from the attempt to assassinate the Emperor on the 14th of January are more disastrous than could have been anticipated. Thence sprang the violenoe of the military addresses, which caused so much displeasure in England, and produced \\u2022 misunderstanding between the two Governments, which has resided on the various markets throughout Franoe, and caused a derangement in mercantile affairs. di Nobody ;ears but that the present difficulty will be pe arranged, and that the former friendly relations will be re-setablished, but it will require \\u2022 inner time to restore that confidence among commercial men which can alone give elasticity to commercial transactions. The Prime of Oude has had an audience of the Emperor of the French. It is said that his Highness \\\" presumed\\\" a little too much. The ambassadors from the two Kings of Siam have also been received in state by the Emperor ; and Prince Maharajah Dhuleep-Singh, ex-King of Lahore, has arrived in Paris. The mit= of Oriental princes and statesmen into Paris begins to be remarked.. A change in the ministry of Foreign Affairs is an. ticipated. Crowds of people have on several days assembled in the Place de la Roquette expecting to see Orsini and his fellow convicts executed. The appeal, however had not yet been decided. THE CASE OF Int. HODGE. \\u2014We are Wormed that since the Emperor Napoleon made the demand of the Sardinian Government that they should surrender Mr. Hodge, on \\u2022 charge of being implicated in the conspiracy to assassinate the Emperor; Sir James Hudson, the British Ambassador at Turin, has written home to state there is not \\u2022 tittle of evidence even to justify Mr. Hodges arrest. The \\\"papers,\\\" we are told, have bean laid before the Attorney-General; meanwhile Mr. Hodges, who 'suffers from pulmonary disonder, is not unlikely to be killed by the confinement while the learned- Attorney-Oeneral and Lord Malmesbury are \\\"communicating.\\\" Paris is beginning to experience, to \\u2022 very considerable extent the results of the new passport regulations regarding the admission of British subjects!. Moreover, hundreds of foreigners have left the cat% Orders are out to the 20,000 mayors of the various communes in Prance to deliverno passport without the personal attenienee of the individual, whose personal peculiarities are to be carefully depicted, in downright pre-Raphaelite style, without any 1.:16'191.d attempt at high art. \",\n          \"THE RECENT FIRE AT THE BLUE  LAST TAVERN.  On Saturday Mr. W. Payne, the coroner of London, held a court of inquiry at the White Horse, Friday-street, Cheapside, respecting the recent fire which occurred upon the premises belonging to Mr. Taylor, the Blue Last Tavern, Distaff-lane. Police-constable 440 (City force) said that on the morning of Thursday last, whilst on duty in Little Distaff-lane, he experienced a strong smell of something burning. He ran up to Mr. Taylor's premises, when he found smoke issuing forth from the shutters. He immediately knocked at the door and cried \\\"Fire !\\\" but five minutes elapsed before he could arouse Mr. Taylor and his family. At length he opened his bed-room window, when some persons in the street called, to him to threw his children out of the window. Witness told him not to do so, but to make haste down stairs. The side door having been opened witness succeeded in helping Mrs. Taylor and the children out. He was then told that the potman was in the upper part of the house, and he immediately went to the stairs for the purpose of making to his bed-room, but the smoke was so dense :that he was unable to get up. He, therefore, went to the bell and rang violently, which awoke the man, and he made his escape over the roof and was taken into an adjoining house. William Maidman, sub-inspector at Watling-street brigade station, proved attending on the morning in question with his engines. The bar, taproom, and bar parlour, were then in flames. The engines were set to work, and the fire was extinguished. Mr. Taylor had told Mtn that the place was overrun with rats, and that he kept lucifer matches in the bar parlour, where no doubt the fire originated. It was quite probable that the rats might have caused the matches to ignite, either by nibbling the boxes or knocking them down. The conductor of the fire-escape, when he arrived at the fire, was so intoxicated as to be unable f\\u2022 render assistance. The Coroner was informed that he had since been dismissed. Verdict ---\\\" That the fire was accidentally caused.\\\"  RISE IN THE VALUE or LAND.\\u2014In the parish of Wensley, and hamlet of Snitterton' at a place called Oaker Hill, are about 100 acres of land (chiefly grazing), the proceeds of the rent of which are appropriated towards the poors-rate of Wensley. Nearly the whole of this land has been in the hands of the same tenants during the last 28 years, it having during that time been let for two periods of 14 years each, by auction, or ticket. The last of the periods named would have expired on Ladyday next, and on Wednesday last the whole was offered by auction in the lots occupied by the respective tenants, nine in number, and who hoped to re-occupy their respective holdings at their former rents. Some of them were, however, doomed to disappointment, as three of the lots were advanced in value by Mr. Thomas Haynes, a tenant to C. Turner, Esq., from the sums respectively hitherto paid per acre as below:\\u2014 Stephen Wall's holding los. per acre, Wm. Greatorex, lsi. per acre, and Godfrey Taylor, 124. per acre, without, however, Mr. Haynes obtaining any land ; and notwithstanding Mr. Greatorex's land was advanced by the bidding named from 2L 9s. per acre to 31. 75., he again took to his previous holding. One lot only went from the previous tenants, Messrs. Benj. and T. Marsden, to Mr. John Holmes, at an advance.\\u2014 Derbyshire Courier. A CANINE THIEF.\\u2014A gentleman, accompanied by a Newfoundland dog, lately entered the office of Messrs. Woodall and Co., bankers, Scarborough, for the purpose of transacting some business. A few minutes afterwards the dog quietly left the office, carrying in his mouth a bag containing 100 sovereigns, which he had. purloined from behind the counter; but, luckily, one of the clerks had watched the four-footed thief, and speedily recovered the stolen treasure.\\u2014Gateshead Observer, \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 1800,\n        \"max\": 1920,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1910,\n          1890\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv('sample_lwm_hmd_mt90_10000.csv')\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE6fnaaRZgzU",
        "outputId": "455d2ecd-93d1-4a66-84bd-03120c72cf02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYvK2zSTcUg4"
      },
      "source": [
        "### Process data\n",
        "\n",
        "To facilitate the analysis we divide the newspaper articles into smaller chunks of 250 words (with a 50-word overlap)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE6QOcPqaf1I"
      },
      "outputs": [],
      "source": [
        "def get_chunks(text: str, size: int=250,step: int=50) -> list:\n",
        "  \"\"\"divide a text into chunks of similar size\n",
        "  Arguments:\n",
        "    text (str): input text\n",
        "    size (int): number of tokens in each chunk\n",
        "    step (int): step size\n",
        "  Returns a list of strings\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  return [' '.join(words[i:i+size]) for i in range(0,len(words),step)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeSqqV6Wa2Ra"
      },
      "source": [
        "We save the chunks in a new list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px_o2GN_Zn8K"
      },
      "outputs": [],
      "source": [
        "# apply chunking to text\n",
        "df['chunks'] = df.text.apply(get_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI7zi3fqZ-3o",
        "outputId": "03c5619d-f399-444d-8c3a-6fa6ec772efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2969, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(df.text[0]),len(df['chunks'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kVFcYiK2j2Z"
      },
      "source": [
        "Next, we reorder the dataframe: each chunk of 250 will be a new row (this increases the number of rows quite a bit, as you may observe)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYGjL1nPZ4ZV",
        "outputId": "f94f53df-a7b3-4676-cc5d-ec10d2819560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(336876, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# reorder the dataframe\n",
        "# with one chunk in each row\n",
        "# instead of the whole text\n",
        "df_chunks = df.explode('chunks')\n",
        "df_chunks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY1ucJhFnguw"
      },
      "source": [
        "## Prompting\n",
        "\n",
        "LLM generate text from an input, usually referred to as a 'prompt', a piece of text we like the model to use as a starting point for predicting novel tokens.\n",
        "\n",
        "When 'chatting' with an LLM we usually provide the model with (at least) two messages: a system and a user prompt or message.\n",
        "\n",
        "**System message**:\n",
        "\n",
        "- **Generic instructions on behaviour**: specify how the model should behave (e.g. be helpful, respectful, neutral) or the role it should play (e.g., a teacher, assistant, or advisor).\n",
        "- **Constraints**: Specific instructions on what the model should avoid or how it should generate responses.\n",
        "- **Context**: Background information or context that remains constant throughout the session to ensure consistency.\n",
        "\n",
        "**User message**:\n",
        "\n",
        "- **Query**: specifies input from the user, such as a question, instruction, or request that the model needs to respond to.\n",
        "- **Dynamic**: changes with each interaction, reflecting the user's immediate needs, questions, or instructions.\n",
        "\n",
        "The Hugging Face chat prompt template allows messages as lists of dictionaries.\n",
        "\n",
        "```python\n",
        "messages [\n",
        " {\n",
        "    \"role\" : \"system\",\n",
        "    \"content\": \"<system prompt here>\"\n",
        " },\n",
        " {\n",
        "    \"role\" : \"user\",\n",
        "    \"content\": \"<user prompt here>\"\n",
        " }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNYCb3IqoRZ7"
      },
      "source": [
        "Define a message by articulating a system and user prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO5PEGlsUukK"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "          You are a helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "          Read the newspaper article attentively and extract the required information.\n",
        "          Each newspaper article is enclosed with triple hashtags (i.e. ###).\n",
        "          Don't make things up! If the information is not in the article then reply 'I don't know'\n",
        "          \"\"\"\n",
        "              },\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"Provide a short description of principal characters portrayed in the newspaper article?\n",
        "\n",
        "                  ###POOR T,i,ENIPAT A 1„k CT  The Poor Law Coirdnissioti(rs have issued a ei; cular,\n",
        "                  dated the 20th instant, stating that they have consulted the Attorney and\n",
        "                  Solicitor-General on the construction of the late Removal Act, and give as the\n",
        "                  result:— I. \" That the proviso to the Ist section of the 9 and 10 Vict., c. 66,\n",
        "                  which sets forth the exceptions to the principal enactments that are to be\n",
        "                  excluded in the computation of time, is net retrospective in its operation, so\n",
        "                  as to apply to cases where the five years\\' residence was complete before the statute.\n",
        "                  2. \" That an interval between the completion of the five years residence and the\n",
        "                  application for the warrant of removal filled up by one of the exceptions contained\n",
        "                  in the proviso will not p event the operation of the statute in restraining the\n",
        "                  removal of the pauper whu had resided for the specified time. 3. \" That orders\n",
        "                  of removal obtained previous to th• passing of the Act, but not then executed\n",
        "                  by the removal of the paupers,###\"\"\"\n",
        "              }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh2iS37UBIOU"
      },
      "outputs": [],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyBwFdkBZ6RG"
      },
      "outputs": [],
      "source": [
        "#help(llm_client.chat_completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MM2Wlv_Vw3y"
      },
      "outputs": [],
      "source": [
        "# # uncomment this code if you want to work locally, comment the other function\n",
        "# def get_completion(messages: list, temperature=.1, top_p=.1) -> str:\n",
        "#   \"\"\"get completion for given system and user prompt\n",
        "#     Arguments:\n",
        "#     messages (list): a list containin a system and user message as\n",
        "#       python dictionaries with keys 'role' and 'content'\n",
        "#     temperature (float): regulate creativity of the text generation\n",
        "#     top_p (float): cummulative probability included in the\n",
        "#       generation process\n",
        "#   \"\"\"\n",
        "#   prompt = pipeline.tokenizer.apply_chat_template(\n",
        "#         messages,\n",
        "#         tokenize=False,\n",
        "#         add_generation_prompt=True\n",
        "#       )\n",
        "\n",
        "#   outputs = pipeline(\n",
        "#     prompt,\n",
        "#     max_new_tokens=256,\n",
        "#     eos_token_id=terminators,\n",
        "#     do_sample=True,\n",
        "#     temperature=temperature,\n",
        "#     top_p=top_p,\n",
        "#       )\n",
        "#   return outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "# uncomment this if you are using the llm_client\n",
        "def get_completion(messages: list, temperature=.1, top_p=.1):\n",
        "    \"\"\"get completion for given system and user prompt\n",
        "      Arguments:\n",
        "        messages (list): a list containin a system and user message as\n",
        "          python dictionaries with keys 'role' and 'content'\n",
        "        temperature (float): regulate creativity of the text generation\n",
        "        top_p (float): cummulative probability included in the\n",
        "          generation process\n",
        "    \"\"\"\n",
        "    outputs = llm_client.chat_completion(\n",
        "        messages=messages,\n",
        "        max_tokens=1024,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p\n",
        "        )\n",
        "    return outputs.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6G6Cbt18lUX",
        "outputId": "6466ce19-28b3-4c7d-f0d6-6109b96043cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the newspaper article, the principal characters mentioned are:\n",
            "\n",
            "1. The Poor Law Commissioners: They are the ones who have issued a circular stating their consultation with the Attorney and Solicitor-General on the construction of the late Removal Act.\n",
            "2. The Attorney-General: He is mentioned as one of the officials consulted by the Poor Law Commissioners on the construction of the Removal Act.\n",
            "3. The Solicitor-General: He is also mentioned as one of the officials consulted by the Poor Law Commissioners on the construction of the Removal Act.\n",
            "4. Paupers: They are the individuals who are the subject of the Removal Act, which deals with their removal from one place to another.\n",
            "\n",
            "Note that there are no specific individuals mentioned in the article, only these groups of people.\n"
          ]
        }
      ],
      "source": [
        "print(get_completion(messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SML4OsbfXIk8"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "- Change the system message and ask the model to reply in medieval French.\n",
        "- Change the user message and ask the model to summarize the article and condense it to one sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CfZ-Q96omxn"
      },
      "outputs": [],
      "source": [
        "# Enter code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq0pWVJXoo10"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am1Ge38tXGP-",
        "outputId": "243c2822-2c13-4cce-a16a-b560d9aaeaf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hear ye, hear ye! I, a humble AI, shall extract the principal characters portrayed in this newspaper article.\n",
            "\n",
            "Verily, I find none. This article appears to be a discussion of the Poor Law Commission's interpretation of the Removal Act, and does not mention any specific individuals. The article is a treatise on the law, outlining the Commission's views on the construction of the Act and its application to various scenarios.\n",
            "\n",
            "Thus, I must reply: \"Je ne sais pas\" (I don't know). There are no principal characters to describe.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"\"\"\n",
        "    You are a helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper article attentively and extract the required information.\n",
        "    Each newspaper article is enclosed with triple hashtags (i.e. ###).\n",
        "    Don't make things up! If the information is not in the article then reply 'I don't know'\n",
        "          Answer in medieval French!\"\"\"\n",
        "          },\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"Summarize the article in one sentence?\n",
        "    ###{df.iloc[0].text}###\"\"\"}\n",
        "]\n",
        "\n",
        "print(get_completion(messages))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNcYq_a-beX1"
      },
      "source": [
        "## Applying text generation to historical documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USeWpL8Ar-UX"
      },
      "source": [
        "### Example 1: Summarize\n",
        "\n",
        "Let's imagine we'd wish to know what happened in January 1899 but won't have time to read all the newspaper issues. Luckily, LLMs excel at summarization!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy5lpuy94eBE"
      },
      "source": [
        "We select all the articles for this January 1899 and save them in a new dataframe. For the purposes of this exercise, we just take a random sample of 20 chunks, otherwise it will take too long to run everything through the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw-N3XoUkRfu",
        "outputId": "0c494245-0e4d-4f66-81f4-9df3822b37de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_small = df_chunks[\n",
        "            (df_chunks.year==1899) & (df_chunks.month==1) # select articles from January 1899\n",
        "                  ].sample(10, random_state=1984).reset_index(drop=True) # we sample a few to keep things simple\n",
        "df_small.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIm6yKDE41Lo"
      },
      "source": [
        "Run the cell below to load the `apply_completions` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJiND9t_dkE0"
      },
      "outputs": [],
      "source": [
        "def apply_completions(item: pd.Series,\n",
        "                      system_message: str,\n",
        "                      user_message: str,\n",
        "                      text_column: str = 'chunks') -> str:\n",
        "  \"\"\"\n",
        "  Function that appl\n",
        "  Argument:\n",
        "    item (pd.Series): row from a pandas Dataframe\n",
        "    system_message (str): system prompt, specifies how the system\n",
        "      should behave in\n",
        "    user_message (str): user prompt, give instruction how to\n",
        "      process each historical. the documents itself will be append\n",
        "      from the 'text_column' argument\n",
        "    text_column (str): name of the text column\n",
        "  \"\"\"\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_message}\n",
        "      ]\n",
        "  messages[1]['content'] += f\"\\n\\n###{item[text_column]}###\"\n",
        "  return  get_completion(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuTEn3245AK"
      },
      "source": [
        "We apply the prompt to the text chunks in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUEjoux9Y3ZV",
        "outputId": "5d9d85d9-222f-4e86-fe92-64590ac9b791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:15<00:00,  1.50s/it]\n"
          ]
        }
      ],
      "source": [
        "tqdm.pandas() # use tqdm to view progress\n",
        "\n",
        "system_message = \"\"\"\n",
        "    You are a helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper article attentively and extract the required information.\n",
        "    Each newspaper article is enclosed with triple hashtags (i.e. ###).\n",
        "    Don't make things up! If the information is not in the article then reply 'I don't know'\n",
        "    \"\"\"\n",
        "user_message = \"Summarize the article in one sentence.\"\n",
        "\n",
        "df_small['completion'] =  df_small.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n54N-ySxjuN2",
        "outputId": "be6f83f8-6d3f-422f-f583-4662830328b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The article is a brief review of an event, praising the performance of the songs and the duties of Bro. John Rennard as the D.C. (presumably a leader or emcee) for adding to the successful enjoyment of the evening.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#print the summaries\n",
        "df_small['completion'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzAyo9DJKhuO"
      },
      "source": [
        "### Example 2: Analyse information about accidents in the news\n",
        "\n",
        "In this example we complicate matters a little bit more.\n",
        "\n",
        "First we retrieve a set of documents based on the date of publications and their content. Then we use an LLMs to ask specific questions about this document ('a baby RAG pipeline, in the sense that we first retrieve and then generate a response to our query').\n",
        "\n",
        "How did accidents in the news change over time? Who is blamed for the accident?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the first step we simple use a regular expression to find reports about accidents."
      ],
      "metadata": {
        "id": "58y6DHQsaPQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDv5HAz1LpW4",
        "outputId": "4a802a04-899c-4e78-b8b6-3e10d12a214b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accidents', 'accident', 'AccIdent']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import re\n",
        "pattern = re.compile(r'\\baccidents?\\b', re.I) # compile a regex\n",
        "pattern.findall('accidents accident AccIdent accidental') # test the regex on a few example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Q74D2MMISw",
        "outputId": "5743dc81-096c-470c-d8ab-89b0514fefb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 336876/336876 [00:11<00:00, 30088.47it/s]\n"
          ]
        }
      ],
      "source": [
        "tqdm.pandas()\n",
        "df_chunks['matches'] = df_chunks.chunks.progress_apply(lambda x: bool(pattern.findall(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpUwL6O3O3cw"
      },
      "source": [
        "Then we retrieve a small sample of accident reports during the 1810s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j0Vs5IxMiUO",
        "outputId": "0d69dbe7-c2c2-4c2c-9817-d6417f19fa38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 16)\n"
          ]
        }
      ],
      "source": [
        "accident_1810s = df_chunks[\n",
        "                    (df_chunks.year.between(1810,1820)) & (df_chunks['matches'] == True)\n",
        "                      ].sample(n=10, random_state=1984)\n",
        "\n",
        "print(accident_1810s.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGHaHfoAPGTH"
      },
      "source": [
        "You can use `.value_counts()` to compute the total number of articles mentioning 'accident' at least once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBvyenk2W7QC",
        "outputId": "065c59a2-514e-4fb0-a04f-06574739115a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matches\n",
              "False    329628\n",
              "True       7248\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>matches</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>329628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>7248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "(df_chunks['matches'] == True).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ATo5AvhmYryp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FtRSk2oT5sc",
        "outputId": "7cdfe707-b71e-4f53-eafc-c104f540e391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.33s/it]\n"
          ]
        }
      ],
      "source": [
        "system_message = \"\"\"\n",
        "    You are a helpful AI that will assist me with analysing and reading newspaper articles.\n",
        "    Read the newspaper article attentively and extract the required information.\n",
        "    Each newspaper article is enclosed with triple hashtags (i.e. ###).\n",
        "    Don't make things up! If the information is not in the article then reply 'I don't know'\n",
        "    Focus on the answer and do not add any unnecessary texts.\"\"\"\n",
        "user_message = \"\"\"Does the article talk about an accident?\n",
        "If yes, who is blamed for causing the accident? Is the accident caused by human error or a fault of the machine?\n",
        "If not, answer 'No accident mentioned' \"\"\"\n",
        "\n",
        "accident_1810s['completion'] =  accident_1810s.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accident_1810s['completion']"
      ],
      "metadata": {
        "id": "ZyNq1BaKapNM",
        "outputId": "975d9e87-605b-4087-d373-30abd5157185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3806                                                                                 No accident mentioned.\n",
              "3806                                                                                 No accident mentioned.\n",
              "3130                                                                                 No accident mentioned.\n",
              "4491                                                                                 No accident mentioned.\n",
              "3130                                                                                 No accident mentioned.\n",
              "966     Yes, the article talks about an accident.\\n\\nThe accidents mentioned are:\\n\\n1. An accident at R...\n",
              "3806    Yes, the article talks about an accident.\\n\\nThe accident is caused by human error, specifically...\n",
              "966     Yes, the article talks about an accident.\\n\\nThe accidents are caused by a bank falling in at th...\n",
              "966     Yes, the article talks about an accident.\\n\\nThe accident is caused by a machine (the bank shoot...\n",
              "4491                                                                                 No accident mentioned.\n",
              "Name: completion, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3806</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3806</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3130</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3130</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>966</th>\n",
              "      <td>Yes, the article talks about an accident.\\n\\nThe accidents mentioned are:\\n\\n1. An accident at R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3806</th>\n",
              "      <td>Yes, the article talks about an accident.\\n\\nThe accident is caused by human error, specifically...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>966</th>\n",
              "      <td>Yes, the article talks about an accident.\\n\\nThe accidents are caused by a bank falling in at th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>966</th>\n",
              "      <td>Yes, the article talks about an accident.\\n\\nThe accident is caused by a machine (the bank shoot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>No accident mentioned.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c46YdAkqU9_K",
        "outputId": "fe13c70d-afaf-4c1e-edf0-4913461967d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"the other four much bruised and cut, six of the eight are in such a state, that their recovery is not etpected. After a length of time, four more were dug up quite dead, and their bodies removed to the canteen for the Coroner's Inquest. A melancholy accident happened at Lisna, in the vicinity of Killileagh, on Tuesday last. As some men were working at a gravel pit for the purpose of repairing roads, the bank shot down and killed two men on the spot ; two more were so desperately bruised by the stuf falling on them, that their recovery is yet very doubtful. Each of the suXerers have lel t a wife and a large helpless family to deplore their loss. A young Lady of the name of LEACH, residing in the neighbourhood of Mary-la-bonne, was shockingly burnt on Thursday night last, by her clothes taking fire by the candle, whilst reading in bed : she lingere&, till the next day, and then expired in the greatest agony.—A Coroner's Jury sat on the body, and brought in a verdict of Accidental Death. At Nancy, in France, the following accident recently happened :—A son of Mr. Dutertre,. a lace.' merchant, was playing with some schoolfellows in his father's house, and, having taken a gun from the counting-house, went through the manual exercise ; not knowing that it was loaded, he presented and discharged it : at that moment his father was entering the room, and the unfortunate parent received\",\n",
              "       'Yes, the article talks about an accident.\\n\\nThe accident is caused by a machine (the bank shooting down) and human error (not knowing the gun was loaded).\\n\\nThe article mentions two accidents:\\n\\n1. At Lisna, two men were killed and two more were seriously injured when the bank of a gravel pit collapsed.\\n2. At Nancy, a son of Mr. Dutertre accidentally shot his father with a gun while playing with friends.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "accident_1810s[['chunks','completion']].iloc[8].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov1ySBNokZmj"
      },
      "source": [
        "### Example 3: Structured Generation\n",
        "\n",
        "Working with these verbose responses if often difficult, especally at scale. Fortunately, we can ask the LLM the respond on a **structured fashion** that we can process more easily.\n",
        "\n",
        "Let's have a look at extracting **biographical information** from newspaper articles.\n",
        "\n",
        "Newspapers contain a lot of biographical information, one could say biography appears as a microgenre in the press. For example, in accident reports we do get some background about the people involved, implicitly (gender) or explicitly (professions or age).\n",
        "\n",
        "Below we use a language model to extract such information from newspaper reports and return it in a predefined format that allows us to analyse newspapers as structured data.\n",
        "\n",
        "Put differently, we use LLMs to extract information similar to automatic annotation, and convert text to JSON format, which is easier to parse with Python.*\n",
        "\n",
        "* You could also use XML if you are more comfortable with this format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKWWeBVXoFaG"
      },
      "outputs": [],
      "source": [
        "df_small = df_chunks[\n",
        "                    (df_chunks['matches'] == True)\n",
        "                      ].sample(n=10, random_state=1984)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCE10sOIZSzt"
      },
      "outputs": [],
      "source": [
        "# df_small['chunks'].iloc[7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDSoGMluRrVa"
      },
      "source": [
        "We rewrite the system prompt and give it a few more instructions on how to respond to our queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAYqIGPOheVr"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\"You are an helpful AI that will assist me with analysing source documents in the form of historical newspaper articles.\n",
        "    Read the newspaper articles attentively and extract structured information formatted as a list of Python dictionaries.\n",
        "    Provide all relevant short source snippets from the documents on which you directly based your answer.\n",
        "    Keep the source snippet short to just a few words and not complete sentences.\n",
        "    The snippet MUST be extracted from the soutce, with spelling and wording identical to the source.\n",
        "    This list of JSON blobs should begin with a \"START\" tag and end with a \"END\" tag.\n",
        "    Each newspaper article will be enclosed with triple hash tags (i.e. ###).\n",
        "    Don't make thigs up! If you don't know the answer, simply return no value\"\"\"\n",
        "\n",
        "\n",
        "user_message = \"\"\"\n",
        "If the article describes a historical accident, extract biographical information about the individuals involved in the accidents.\n",
        "Return a list of Python dictionaries for each individual which records important personal attributes such gender, age and profession, and others that are relevant.\n",
        "Each attribute is a key in a dictionary.\n",
        "Record personal attribures as dictionaries as shown in the example below.\n",
        "Also add one key with \"outcome\" that records what happened to person (\"drowned\", \"survived\", \"injured\")\n",
        "Add a confidence score as a float between 0 and 1 for each snippet extracted.\n",
        "Under \"source_snippets\" collect text fragments that record what happened to person involved.\n",
        "\n",
        "START\n",
        "[\n",
        "  {\n",
        "  \"name\" : { \"value\": answer,\"source\": source_snippet, \"confidence\": your_confidence_score },\n",
        "  \"gender\" : { \"value\": answer,\"source\": source_snippet, \"confidence\": your_confidence_score },\n",
        "  \"profession\" :{ \"value\": answer,\"source\": source_snippet, \"confidence\": your_confidence_score },\n",
        "  ... other attributes ...,\n",
        "  \"outcome\" : { \"value\": answer,\"source\": source_snippet, \"confidence\": your_confidence_score },\n",
        "  \"summary\": { \"value\" :summary, \"confidence\" : your_confidence_score }\n",
        "  },\n",
        "...]\n",
        "END\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S9M6ojCd0d7",
        "outputId": "76cd6b82-b231-4ff8-f76f-8dee6c3d160b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START\n",
            "[\n",
            "  {\n",
            "    \"name\" : {\"value\": \"The Rev. G. M. Gordon\", \"source\": \"who as killed in the sortie from Candahar\", \"confidence\": 0.9},\n",
            "    \"gender\" : {\"value\": \"male\", \"source\": \"\", \"confidence\": 0.8},\n",
            "    \"profession\" : {\"value\": \"clergyman\", \"source\": \"The Rev. G. M. Gordon\", \"confidence\": 0.9},\n",
            "    \"outcome\" : {\"value\": \"killed\", \"source\": \"who as killed in the sortie from Candahar\", \"confidence\": 0.9},\n",
            "    \"source_snippets\" : [\"who as killed in the sortie from Candahar\"],\n",
            "    \"summary\" : {\"value\": \"The Rev. G. M. Gordon was killed in the sortie from Candahar\", \"confidence\": 0.9}\n",
            "  },\n",
            "  {\n",
            "    \"name\" : {\"value\": \"Duke of Connaught\", \"source\": \"The Duke of Connaught\", \"confidence\": 0.9},\n",
            "    \"gender\" : {\"value\": \"male\", \"source\": \"\", \"confidence\": 0.8},\n",
            "    \"profession\" : {\"value\": \"royal\", \"source\": \"The Duke of Connaught\", \"confidence\": 0.9},\n",
            "    \"outcome\" : {\"value\": \"injured\", \"source\": \"Beyond the shaking, however, the Duke was little the worse for the mishap\", \"confidence\": 0.8},\n",
            "    \"source_snippets\" : [\"The Duke of Connaught\", \"Beyond the shaking, however, the Duke was little the worse for the mishap\"],\n",
            "    \"summary\" : {\"value\": \"The Duke of Connaught was thrown from his horse and injured\", \"confidence\": 0.8}\n",
            "  },\n",
            "  {\n",
            "    \"name\" : {\"value\": \"Rodwell\", \"source\": \"three gentlemen named Rodwell\", \"confidence\": 0.8},\n",
            "    \"gender\" : {\"value\": \"male\", \"source\": \"\", \"confidence\": 0.8},\n",
            "    \"profession\" : {\"value\": \"gentleman\", \"source\": \"three gentlemen named Rodwell\", \"confidence\": 0.8},\n",
            "    \"outcome\" : {\"value\": \"drowned\", \"source\": \"A yacht suddenly capsized off Hastings on Tuesday afternoon, and three gentlemen named Rodwell, Lindsey, and Docwra, and a boatman named Swaine, were drowned\", \"confidence\": 0.9},\n",
            "    \"source_snippets\" : [\"three gentlemen named Rodwell\", \"A yacht suddenly capsized off Hastings on Tuesday afternoon, and three gentlemen named Rodwell, Lindsey, and Docwra, and a boatman named Swaine, were drowned\"],\n",
            "    \"summary\" : {\"value\": \"Rodwell was one of the three gentlemen who drowned in a yacht capsizing\", \"confidence\": 0.8}\n",
            "  },\n",
            "  {\n",
            "    \"name\" : {\"value\": \"Lindsey\", \"source\": \"three gentlemen named Rodwell, Lindsey, and Docwra\", \"confidence\": 0.8},\n",
            "    \"gender\" : {\"value\": \"male\", \"source\": \"\", \"confidence\": 0.8},\n",
            "    \"profession\" : {\"value\": \"gentleman\", \"source\": \"three gentlemen named Rodwell, Lindsey, and Docwra\", \"confidence\": 0.8},\n",
            "    \"outcome\" : {\"value\": \"drowned\", \"source\": \"A yacht suddenly capsized off Hastings on Tuesday afternoon, and three gentlemen named Rodwell, Lindsey, and Docwra, and a boatman named Swaine, were drowned\", \"confidence\": 0.9},\n",
            "    \"source_snippets\" : [\"three gentlemen named Rodwell, Lindsey, and Docwra\", \"A yacht suddenly capsized off Hastings on Tuesday afternoon, and three gentlemen named Rodwell, Lindsey, and Docwra, and a boatman named Swaine, were drowned\"],\n",
            "    \"summary\" : {\"value\": \"Lindsey was one of the three gentlemen who drowned in a yacht capsizing\", \"confidence\": 0.8}\n",
            "  },\n",
            "  {\n",
            "    \"name\" : {\"value\": \"Docwra\", \"source\": \"three gentlemen named Rodwell, Lindsey, and Docwra\", \"confidence\": 0.8},\n",
            "    \"gender\" : {\"value\": \"male\", \"source\": \"\", \"confidence\": 0.8},\n",
            "    \"profession\" : {\"value\": \"gentleman\", \"source\": \"three gentlemen named Rodwell, Lindsey, and Docwra\", \"confidence\": 0.8},\n",
            "    \"outcome\" : {\"value\": \"drowned\", \"source\": \"A yacht suddenly capsized off Hastings on Tuesday afternoon, and three gentlemen named Rodwell, Lindsey, and Docwra, and a boat\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_message + f'\\n\\n###{df_small[\"chunks\"].iloc[4]}###'}\n",
        "      ]\n",
        "print(get_completion(messages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDw5FzAta9Ku",
        "outputId": "1cc31bd1-bb48-41ea-dd62-1d9cbedb2c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:44<00:00,  4.41s/it]\n"
          ]
        }
      ],
      "source": [
        "df_small['completion'] =  df_small.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJGmFs9Qq_Tu",
        "outputId": "e268cebe-78fe-467d-9cf5-10daf53f243f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9969    START\\n[\\n  {\\n    \"name\" : {\"value\" : \"James Turner\", \"source\" : \"Subsequently a man who, it is...\n",
            "3526    START\\n[\\n  {\\n    \"name\" : {\"value\": \"James Heng\", \"source\": \"ACCIDENT AT WOOLWICH DOCKYARD;— a...\n",
            "8563    START\\n[\\n  {\\n    \"name\" : {\"value\": \"Edward Ball\", \"source\": \"that of a young man named Edward...\n",
            "7666    START\\n[\\n  {\\n    \"name\" : {\"value\": \"unknown\", \"source\": \"A frightful accident occurred on Sat...\n",
            "9068    START\\n[\\n  {\\n    \"name\" : {\"value\": \"The Rev. G. M. Gordon\", \"source\": \"who as killed in the s...\n",
            "3438                                                                                             END\\n\\n###\n",
            "7306    START\\n[\\n  {\\n    \"name\" : {\"value\": \"Miles Barnes\", \"source\": \"the body of Miles Barnes\", \"con...\n",
            "3077    START\\n[\\n  {\\n    \"name\" : {\"value\": \"Sareh Bunyan\", \"source\": \"On Friday an inquest was held i...\n",
            "5963    START\\n[\\n  {\\n    \"name\" : {\"value\": \"Samuel Birtwistle\", \"source\": \"A youth named Samuel Birtw...\n",
            "5177    END\\n\\nSTART\\n[\\n  {\\n    \"name\" : {\"value\": None, \"source\": None, \"confidence\": 0.0},\\n    \"gen...\n",
            "Name: completion, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df_small['completion'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocO1ody2SAWt"
      },
      "source": [
        "To convert the response to a Python data type, we use the `eval_completion` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmyQ5u4NIIT_",
        "outputId": "51d9253a-1d29-4712-8da5-7cba825b2577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unterminated string literal (detected at line 38) (<string>, line 38)\n",
            "name 'END' is not defined\n"
          ]
        }
      ],
      "source": [
        "def eval_completion(completion: str) -> list:\n",
        "  \"\"\"Convert the completion as string to a Python list\n",
        "  Argument:\n",
        "      completion (str): structured generation by LLM\n",
        "  \"\"\"\n",
        "  try:\n",
        "    return eval(completion.split('START')[-1].strip().rstrip('END').strip())\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return []\n",
        "\n",
        "df_small['completion_eval'] = df_small['completion'].apply(eval_completion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBwc1JXhSgK1"
      },
      "source": [
        "Let's have a bit closer look at some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0boRbvyXIsdW",
        "outputId": "99341cda-8ca6-4894-e3ba-533cd4a2f231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9969    [{'name': {'value': 'James Turner', 'source': 'Subsequently a man who, it is alleged, first rais...\n",
              "3526    [{'name': {'value': 'James Heng', 'source': 'ACCIDENT AT WOOLWICH DOCKYARD;— accident occurred y...\n",
              "8563    [{'name': {'value': 'Edward Ball', 'source': 'that of a young man named Edward Ball', 'confidenc...\n",
              "7666    [{'name': {'value': 'unknown', 'source': 'A frightful accident occurred on Saturday week at the ...\n",
              "9068                                                                                                     []\n",
              "3438                                                                                                     []\n",
              "7306    [{'name': {'value': 'Miles Barnes', 'source': 'the body of Miles Barnes', 'confidence': 1.0}, 'g...\n",
              "3077    [{'name': {'value': 'Sareh Bunyan', 'source': 'On Friday an inquest was held in New Gravel-lane ...\n",
              "5963    [{'name': {'value': 'Samuel Birtwistle', 'source': 'A youth named Samuel Birtwistle', 'confidenc...\n",
              "5177    [{'name': {'value': None, 'source': None, 'confidence': 0.0}, 'gender': {'value': None, 'source'...\n",
              "Name: completion_eval, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>completion_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9969</th>\n",
              "      <td>[{'name': {'value': 'James Turner', 'source': 'Subsequently a man who, it is alleged, first rais...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3526</th>\n",
              "      <td>[{'name': {'value': 'James Heng', 'source': 'ACCIDENT AT WOOLWICH DOCKYARD;— accident occurred y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8563</th>\n",
              "      <td>[{'name': {'value': 'Edward Ball', 'source': 'that of a young man named Edward Ball', 'confidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7666</th>\n",
              "      <td>[{'name': {'value': 'unknown', 'source': 'A frightful accident occurred on Saturday week at the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9068</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3438</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7306</th>\n",
              "      <td>[{'name': {'value': 'Miles Barnes', 'source': 'the body of Miles Barnes', 'confidence': 1.0}, 'g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3077</th>\n",
              "      <td>[{'name': {'value': 'Sareh Bunyan', 'source': 'On Friday an inquest was held in New Gravel-lane ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5963</th>\n",
              "      <td>[{'name': {'value': 'Samuel Birtwistle', 'source': 'A youth named Samuel Birtwistle', 'confidenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5177</th>\n",
              "      <td>[{'name': {'value': None, 'source': None, 'confidence': 0.0}, 'gender': {'value': None, 'source'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df_small['completion_eval']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS6AD3QbpL0t",
        "outputId": "e0ab7c61-a6fe-4f9e-8987-2a2f3bcfbd2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df_small['completion_eval'].iloc[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXbqMNySJ2ii"
      },
      "source": [
        "Lastly we can have a bit closer look at how the language model processes the text by highlighting the fragments on which it based its answers. This can help us with\n",
        "- creating automatic pre-annotation\n",
        "- figuring out how the pipeline could be improved\n",
        "- close-reading large amounts of text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZD1DtdgJqPG"
      },
      "outputs": [],
      "source": [
        "row = df_small.iloc[1]\n",
        "html_output = row['chunks']\n",
        "for p_dict in row['completion_eval']:\n",
        "  for attr, attr_dict in p_dict.items():\n",
        "    try:\n",
        "      if isinstance(attr_dict, dict):\n",
        "        if attr_dict.get('confidence',.0) > .5 and attr_dict.get(\"source\",None):\n",
        "          html_output = re.sub(str(attr_dict['source']),\n",
        "                   f'<span style=\"background-color: yellow;\">{attr_dict[\"source\"]}</span>', html_output)\n",
        "    except Exception as e:\n",
        "      print(e,attr_dict)\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41udlbVTLeLr",
        "outputId": "48154097-4b0e-4bf4-b79e-a96bb1c05e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "clerk of the peace to every petty sessional division in the Riding. The chief constable stated, however, that according to the information he received the cattle plague was extending in certain localities. OXFORD COUNTY GAOL.—At the Michalemas Quarter Session held yesterday, and which an unusually large number of magistrates attended, the deputy governor of the county gaol (Mr. Calverly) was unanimously elected governor, in the room of Major Ogilvie, resigned. At the same time Mr. Mores, who had officiated as clerk at the gaol for the last sixteen years, was unanimously elected deputy governor. <span style=\"background-color: yellow;\">ACCIDENT AT WOOLWICH DOCKYARD;— accident occurred yesterday to James Heng</span> r' aAlabourer, serious Demopckyloyaerdd,awt who oheit satpepamearsfawctasoryat dweoprakrtminenthteshed ofe eWoolwichwhe re massive 4i-inch iron plates used for ship building are bent by machinery, when his clothing by some means was caught in a drilling machine, and he was whirled rapidly round, <span style=\"background-color: yellow;\">breaking three of his ribs and fracturing his skull</span>. The sufferer was immediately removed to the Royal Marine Infirmary, where he now remains in a precarious condition. [ADVERTISEMENT.]—That the fearful annual mortality of 68,0G0 youngincehtleidadrenotatinydindgeibiclaitnedlpy to pillsofersons and medicines, allagmesmicaiynebs, which, be arrested,hioif, though apparently relieving the patient, have in h reality no o,her tendency than that of increasing debility, upon ona p odi nn eiwith: ba eieht thetthheevdi atanlgfe force re eo f harmoniousbl fye, we were simply to study how dlmpartingennteowt tahnedwphuorlee iblood,rarne depends, has been successfully proved by Du Barry's Invalids' and Infants' Food, the Revalenta Arabica, and its thousands of cures"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML(html_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWAog9xdpG_q"
      },
      "source": [
        "### Example 4: OCR correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmvJn6ZlOdC4"
      },
      "source": [
        "Lastly, let's use LLM to help us with a longstanding problem in digital humanities, improving OCR quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5N8e2qdpKBZ"
      },
      "outputs": [],
      "source": [
        "df_small_bad_ocr = df_chunks.sort_values('ocrquality', ascending=True)[:1000].sample(n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JXH_oypolYi",
        "outputId": "bf73932f-18a9-45e8-9652-73c28a93167d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:16<00:00,  7.61s/it]\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are an helpful AI and provide truthful correction of historical text.\"\n",
        "\n",
        "user_message = \"\"\"Transcribe the text and correct typos and errors in the text caused by bad optical character recognition (OCR).\n",
        "Do not add any information that is not in the original text!\"\"\"\n",
        "\n",
        "df_small_bad_ocr['completion'] = df_small_bad_ocr.progress_apply(apply_completions,system_message=system_message, user_message=user_message, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjFbCSDYtNx-",
        "outputId": "562ef22e-5929-4253-960c-54c5f33c7d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from Harrow; Mr. and Miss Afansergh, at Gould's Hotel, Jermyn-street, from Paris; Captain Patterson, at ditto, from Bath ; Samuel Peach, Esq., at Burlington Hotel, Old Burlington and Cork.:streets, from Warwickshire ; J. Cano, Esq. at ditto, from Ireland. CUANGEL—The Earl and Countess of Sefton and the Ladies Molyneux, for their seat, Stoke Farm, Berke ; the Countess of Mansfield, for her Villa at Twickenham ; Lord Lynedock, from his seat, Cosgrove Priory, for the Marquis of Anglesey's, Beau Desert, Staffordshire; Lord Meneaster, from Melton Mowbray, for his seat, in Cumberland ; Augustus Atkyns, Esq. from Farnborough Hill, near Bagshot, to Arreton Vicarage, near Newport, Isle of Wight; the Rev. Dr. Wynne, from Warne's Hotel; Mrs. Fletcher and family, from ditto; Mrs. Walker and family, from ditto, for North Wales; the Countess of Golflird, from the St. George's Hotel, Albemarle-street, for her seat, Brompton Park, Huntingdon. The Marchioness Dowager of Salisbury's Convex.sazione, on Sunday evening, was attended by the Russian Prince Puckler-Muskau, the Prince and Princess Esterhazy, the Prince and Princess Polignac, the Princess Lieven, the Ambassador from Portugal, the Ministers from Naples, Saxony, Wirtemberg, Prussia, Sardinia, Sweden, and the Netherlands, Countess Ludolff, Sir George Warrender, Colonel and Mrs. Malcolm, Lady Fitzroy Somerset, Earl of Westmorland, Mr. and Mrs. D'Anshaw, Countess Tankerville, Mr. Gordon, Lady Anne Becket, Mr. S. Smith, General Capel, Madame and Mademoiselle Feick, Colonel Whatley, Countess of Essex, Mr. de Neuman, Count Lothim, Mr. and Mrs. Omer Moreau, Countess de Chestalgar, Lady Elizabeth Stuart, Countess d'Alcudia, Monsieur\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df_small_bad_ocr.iloc[4]['chunks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLsWShc7tKGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22ce451-a421-4547-85d3-b625bcec1fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the transcribed text with corrections for typos and OCR errors:\n",
            "\n",
            "###From Harrow; Mr. and Miss Afansiegh, at Gould's Hotel, Jermyn Street, from Paris; Captain Patterson, at ditto, from Bath; Samuel Peach, Esq., at Burlington Hotel, Old Burlington Street and Cork Street, from Warwickshire; J. Cano, Esq., at ditto, from Ireland.\n",
            "\n",
            "CUANGEL—The Earl and Countess of Sefton and the Ladies Molyneux, for their seat, Stoke Farm, Berkshire; the Countess of Mansfield, for her villa at Twickenham; Lord Lynedoch, from his seat, Cosgrove Priory, for the Marquis of Anglesey's, Beau Desert, Staffordshire; Lord Manners, from Melton Mowbray, for his seat, in Cumberland; Augustus Atkyns, Esq., from Farnborough Hill, near Bagshot, to Arreton Vicarage, near Newport, Isle of Wight; the Rev. Dr. Wynne, from Warne's Hotel; Mrs. Fletcher and family, from ditto; Mrs. Walker and family, from ditto, for North Wales; the Countess of Gough, from the St. George's Hotel, Albemarle Street, for her seat, Brompton Park, Huntingdon.\n",
            "\n",
            "The Marchioness Dowager of Salisbury's Conversazione, on Sunday evening, was attended by the Russian Prince Pückler-Muskau, the Prince and Princess Esterházy, the Prince and Princess Polignac, the Princess Lieven, the Ambassador from Portugal, the Ministers from Naples, Saxony, Württemberg, Prussia, Sardinia, Sweden, and the Netherlands, Countess Ludolf, Sir George Warrender, Colonel and Mrs. Malcolm, Lady Fitzroy Somerset, Earl of Westmorland, Mr. and Mrs. D'Anshaw, Countess Tankerville, Mr. Gordon, Lady Anne Beckett, Mr. S. Smith, General Capel, Madame and Mademoiselle Feick, Colonel Whatley, Countess of Essex, Mr. de Neuman, Count Lothian, Mr. and Mrs. Omer Moreau, Countess de Chestalgar, Lady Elizabeth Stuart, Countess d'Alcudia, Monsieur###\n"
          ]
        }
      ],
      "source": [
        "print(df_small_bad_ocr.iloc[4]['completion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rc0U8WqsXiA",
        "outputId": "31b19940-55b4-4aec-915c-7d1dcd540344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"to the south of well-searched tracts, and has been approache I by vessels that have returned without loss, has never yet been explored. _ _ Supported by the advice of those experienced Arctic seamen, in, whom she has every reason to confide, Lady Franklin makes this last effort to clear away the mystery that shrouds tho' fate of her husband and his crews, and possibly to reszue from their iusulatedley abode among the Esquiniaux some of his younger companions, who may still be prolonging a dreary existence. • On such an occasion we, whose names are hereunto sub. scribed, feel confident that this our appeal will not remain unanswered by the British people, who will, we doubt not, tender to the widow of the illustrious navigator that :sympathy which his fame and her devotion must call t ,rth, and will aid her .in • carrying out' an enterprise' involving, as we believe, the honour of the nation. We earnestly, therefore, entreat our countrymen to unite with us in contributing to this noble object. Roderick Murchison, Pres. Royal Geographical Society, ; Francis Beaufort, Rear-Admiral, F.R.S. ' Wrottesley, Pres. Rl.-Soeiety ; Edward Sabine, M.-General, Treas. RI. Society, P.R.G.S. ; Robert Brown, F.R.S., V.p.L.s. ; Richard Collinson, Captain R.N., F.R.G.S. ; John Barrow, F. R. S. , F. R. G. S. ,IPTIONS. C. Coote, zo - 0 0 Mrs. J. M. Batty 1 1 0 J. C. Janson, Esq.: '5 5 0 C. Bahbage, F.R.S. 10 0 0 Lieut.R N. Hughes 2 0\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df_small_bad_ocr.iloc[3]['chunks']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5BxeDnttYZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7c65f94f-aaaf-45d2-8e84-4b986fa1359f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here is the transcribed and corrected text:\\n\\n###To the south of well-searched tracts, and has been approached by vessels that have returned without loss, has never yet been explored.\\n\\nSupported by the advice of those experienced Arctic seamen, in whom she has every reason to confide, Lady Franklin makes this last effort to clear away the mystery that shrouds the fate of her husband and his crew, and possibly to rescue from their isolated abode among the Esquimaux some of his younger companions, who may still be prolonging a dreary existence.\\n\\n• On such an occasion we, whose names are hereunto subscribed, feel confident that this our appeal will not remain unanswered by the British people, who will, we doubt not, tender to the widow of the illustrious navigator that sympathy which his fame and her devotion must call forth, and will aid her in carrying out an enterprise involving, as we believe, the honour of the nation.\\n\\nWe earnestly, therefore, entreat our countrymen to unite with us in contributing to this noble object.\\n\\nRoderick Murchison, Pres. Royal Geographical Society,\\nFrancis Beaufort, Rear-Admiral, F.R.S.\\nWrottesley, Pres. Rl.-Society;\\nEdward Sabine, M.-General, Treas. RI. Society, P.R.G.S.\\nRobert Brown, F.R.S., V.p.L.s.\\nRichard Collinson, Captain R.N., F.R.G.S.\\nJohn Barrow, F.R.S., F.R.G.S.\\nSUBSCRIPTIONS:\\nC. Coote, £0 0 0\\nMrs. J. M. Batty, £1 1 0\\nJ. C. Janson, Esq.: £5 5 0\\nC. Bahmage, F.R.S., £10 0 0\\nLieut. R. N. Hughes, £2 0 0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df_small_bad_ocr.iloc[3]['completion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpChnh_7q-gF"
      },
      "outputs": [],
      "source": [
        "df_small_bad_ocr.to_csv('newspaper_ocr_corrected.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzavYR10sI_o"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Experiment with your own system and user message! Have fun :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyrtAOQ24cJO"
      },
      "outputs": [],
      "source": [
        "# enter code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What if things don't work?\n",
        "\n",
        "- Use larger models (see example below for using the OpenAI API)\n",
        "- Model fine-tuning on real or synthetic data. An example [here](https://huggingface.co/blog/mlabonne/sft-llama3)"
      ],
      "metadata": {
        "id": "21GtJijJbwlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "yzr930-ZeNtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "SY4lisOheLoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small_bad_ocr.iloc[4]['chunks']"
      ],
      "metadata": {
        "id": "UnMGcBDvdHiV",
        "outputId": "54f51c60-044c-4d6a-c039-8b06e04f9bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from Harrow; Mr. and Miss Afansergh, at Gould's Hotel, Jermyn-street, from Paris; Captain Patterson, at ditto, from Bath ; Samuel Peach, Esq., at Burlington Hotel, Old Burlington and Cork.:streets, from Warwickshire ; J. Cano, Esq. at ditto, from Ireland. CUANGEL—The Earl and Countess of Sefton and the Ladies Molyneux, for their seat, Stoke Farm, Berke ; the Countess of Mansfield, for her Villa at Twickenham ; Lord Lynedock, from his seat, Cosgrove Priory, for the Marquis of Anglesey's, Beau Desert, Staffordshire; Lord Meneaster, from Melton Mowbray, for his seat, in Cumberland ; Augustus Atkyns, Esq. from Farnborough Hill, near Bagshot, to Arreton Vicarage, near Newport, Isle of Wight; the Rev. Dr. Wynne, from Warne's Hotel; Mrs. Fletcher and family, from ditto; Mrs. Walker and family, from ditto, for North Wales; the Countess of Golflird, from the St. George's Hotel, Albemarle-street, for her seat, Brompton Park, Huntingdon. The Marchioness Dowager of Salisbury's Convex.sazione, on Sunday evening, was attended by the Russian Prince Puckler-Muskau, the Prince and Princess Esterhazy, the Prince and Princess Polignac, the Princess Lieven, the Ambassador from Portugal, the Ministers from Naples, Saxony, Wirtemberg, Prussia, Sardinia, Sweden, and the Netherlands, Countess Ludolff, Sir George Warrender, Colonel and Mrs. Malcolm, Lady Fitzroy Somerset, Earl of Westmorland, Mr. and Mrs. D'Anshaw, Countess Tankerville, Mr. Gordon, Lady Anne Becket, Mr. S. Smith, General Capel, Madame and Mademoiselle Feick, Colonel Whatley, Countess of Essex, Mr. de Neuman, Count Lothim, Mr. and Mrs. Omer Moreau, Countess de Chestalgar, Lady Elizabeth Stuart, Countess d'Alcudia, Monsieur\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='sk-...')"
      ],
      "metadata": {
        "id": "eChdTy-fsOiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Correct the text below.\"},\n",
        "    {\"role\": \"user\", \"content\": df_small_bad_ocr.iloc[4]['chunks']}\n",
        "  ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "bz78uSV0bwRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "-f-JzBjysGnP",
        "outputId": "3d50cdb7-eb81-4809-c1a6-02fba79db9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From Harrow; Mr. and Miss Afansergh, at Gould's Hotel, Jermyn Street, from Paris; Captain Patterson, at the same, from Bath; Samuel Peach, Esq., at Burlington Hotel, Old Burlington and Cork Streets, from Warwickshire; J. Cano, Esq., at the same, from Ireland.\n",
            "\n",
            "CHANGES—The Earl and Countess of Sefton and the Ladies Molyneux, for their seat, Stoke Farm, Berkshire; the Countess of Mansfield, for her villa at Twickenham; Lord Lynedoch, from his seat, Cosgrove Priory, for the Marquis of Anglesey's Beau Desert, Staffordshire; Lord Meneaster, from Melton Mowbray, for his seat in Cumberland; Augustus Atkyns, Esq., from Farnborough Hill, near Bagshot, to Arreton Vicarage, near Newport, Isle of Wight; the Rev. Dr. Wynne, from Warne's Hotel; Mrs. Fletcher and family, from the same; Mrs. Walker and family, from the same, for North Wales; the Countess of Gifford, from the St. George's Hotel, Albemarle Street, for her seat, Brompton Park, Huntingdon.\n",
            "\n",
            "The Marchioness Dowager of Salisbury's conversazione, on Sunday evening, was attended by the Russian Prince Puckler-Muskau, the Prince and Princess Esterhazy, the Prince and Princess Polignac, the Princess Lieven, the Ambassador from Portugal, the Ministers from Naples, Saxony, Wurttemberg, Prussia, Sardinia, Sweden, and the Netherlands, Countess Ludolf, Sir George Warrender, Colonel and Mrs. Malcolm, Lady Fitzroy Somerset, Earl of Westmorland, Mr. and Mrs. D'Anshaw, Countess Tankerville, Mr. Gordon, Lady Anne Becket, Mr. S. Smith, General Capel, Madame and Mademoiselle Feick, Colonel Whatley, Countess of Essex, Mr. de Neumann, Count Lothim, Mr. and Mrs. Omer Moreau, Countess de Chestalgar, Lady Elizabeth Stuart, and Countess d'Alcudia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzdNxsZPsKr5"
      },
      "source": [
        "# Fin."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tq0pWVJXoo10"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a2f073bffe24c87abb9d81547b43311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2fb19d6b55c42a893b698ce22c02544",
              "IPY_MODEL_ff43f1349df542bc9dbe21a98d32a809",
              "IPY_MODEL_2e5dbb5d6c5d45afba265047753b9e20"
            ],
            "layout": "IPY_MODEL_0e050d898f1643ca8a5c074a554286b4"
          }
        },
        "b2fb19d6b55c42a893b698ce22c02544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56faa1ef2ea6445a8fdf1614e75e1c08",
            "placeholder": "​",
            "style": "IPY_MODEL_1451f4284e85462390c14e6057014c95",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ff43f1349df542bc9dbe21a98d32a809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6301aad1e0c046cba777e8eba409d55a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28b8de963d02438ca4a9ce3ca7ae7f04",
            "value": 4
          }
        },
        "2e5dbb5d6c5d45afba265047753b9e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03284201464b44d7b5d200035c3404c2",
            "placeholder": "​",
            "style": "IPY_MODEL_4010561ef6e94f0caf25aa8166a49b06",
            "value": " 4/4 [00:11&lt;00:00,  2.38s/it]"
          }
        },
        "0e050d898f1643ca8a5c074a554286b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56faa1ef2ea6445a8fdf1614e75e1c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1451f4284e85462390c14e6057014c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6301aad1e0c046cba777e8eba409d55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b8de963d02438ca4a9ce3ca7ae7f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03284201464b44d7b5d200035c3404c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4010561ef6e94f0caf25aa8166a49b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}