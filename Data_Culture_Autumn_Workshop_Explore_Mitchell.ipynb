{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSYkzI558H7sMDausnzv22",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasparvonbeelen/data-culture-newspapers/blob/directories/Data_Culture_Autumn_Workshop_Explore_Mitchell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on Session\n",
        "## ðŸŒ» Fun with Press Directories ðŸ¦„\n",
        "\n",
        "What we will do in this session:\n",
        "- Introduce notebooks and pandas as a framework for working with historical tabular data.\n",
        "- Investigate the content of the digitized Press Directories.\n",
        "- Explore a few case studies that demonstrate how to use the directories for research on the press.\n",
        "\n",
        "![](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExMGExemc4c3ZhaDVzNTZlM2JnNDFvcm11YW53bmY1cnk3cGM0bm40ZiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/lTpme2Po0hkqI/giphy.gif)"
      ],
      "metadata": {
        "id": "DM5je7bXzm33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First of all... Notebooks <3\n",
        "\n",
        "...what am I looking at here?\n"
      ],
      "metadata": {
        "id": "LstFFd0k1wJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Welcome to* **Markdown**\n",
        "\n",
        "You write text..."
      ],
      "metadata": {
        "id": "5i_X_KBD17l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â and Python code\n",
        "print('Hello, World')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzfUWplg2PPI",
        "outputId": "7e41d546-c539-450e-89d3-0aee6d6eaa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Â text is Python is called strings, abbreviated as str\n",
        "type('Hello, World')"
      ],
      "metadata": {
        "id": "6nJjeVuRwRav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â but of course, Python also accepts numbers!\n",
        "4 + 2"
      ],
      "metadata": {
        "id": "wVaWan9JsTRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â or floats\n",
        "4.0 + 3.42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty8SLCZlwZq5",
        "outputId": "ac7901f2-3e94-4ebd-d14c-d51d91a42df3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.42"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Â saving information in a variable\n",
        "a = 'hello'\n",
        "print(a)"
      ],
      "metadata": {
        "id": "EimP8Fwg4lYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â— You will need to run all the cells in order â—"
      ],
      "metadata": {
        "id": "deaiNStHArQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you know enough technical stuff to follow along."
      ],
      "metadata": {
        "id": "gRea-zKF4T5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â Finding the Directories Online\n",
        "\n"
      ],
      "metadata": {
        "id": "Fit5zWvK85z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can consult the directories [online](https://bl.iro.bl.uk/concern/datasets/adcef12a-bb3d-40d9-871d-5784022a77e8)\n",
        "\n",
        "Let's have a look at the documentation first and open the attached PDF.\n",
        "\n",
        "We will have a closer look at how to explore the directories using code (Python). However, if you are more comfortable with Excel (ðŸ˜µâ€ðŸ’«) feel free to explore the data there (life is short)."
      ],
      "metadata": {
        "id": "IbcB_Cte8wXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Python\n",
        "\n",
        "This session is not an introduction to Python or programming.\n",
        "\n",
        "The goal is to show what you can do with the Press Directories, using a bit of code.\n",
        "\n",
        "For those who know Python, relax and follow along.\n",
        "\n",
        "Those new to coding should try to understand what is happening and focus on the outcomes (not the code). All code is explained with comments, but don't try to understand the syntax.\n",
        "\n",
        "If you are intrigued, I can recommend [this book](https://jakevdp.github.io/PythonDataScienceHandbook/) if you want more and work with data frames/tabular data in Python!"
      ],
      "metadata": {
        "id": "J9OhIOxPiwcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the Directories with Pandas\n",
        "\n",
        "![pandas](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExanp1NHdzbnA4cWUxdGNoazYwN2c0Y2E5am96YW5rNTNkd2Q4YXJtdiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/aCa8jFalHHJvi/giphy.gif)"
      ],
      "metadata": {
        "id": "nfcZ83Tz4Lqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â Importing data"
      ],
      "metadata": {
        "id": "HeLp4qw0Gd0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pandas library\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PWkoBThF6Ik6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open the CSV file given the URL\n",
        "#Â you can also download the file and use it locally\n",
        "df = pd.read_csv('https://bl.iro.bl.uk/downloads/da65047c-4d62-4ab7-946f-8e61e5f6f331?locale=en', index_col=0)"
      ],
      "metadata": {
        "id": "peD6cFRq8WI8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the NaN (not a number) values with empty spaces\n",
        "# otherwise code will break later on\n",
        "df.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "vL2efNw3Qz2a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "zanm8w4KzPpT"
      },
      "outputs": [],
      "source": [
        "# show the number rows and columns\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Â example of first two rows\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "K9T-7W-GACCz"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â random sample of 2 rows\n",
        "df.sample(2)"
      ],
      "metadata": {
        "id": "Ta3Le93tpz1a"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show all the column names\n",
        "df.columns"
      ],
      "metadata": {
        "id": "tLiN0zJ4AGAP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case Study 1: How old is the average newspaper title?\n",
        "\n",
        "**Question**: How 'old' is the average newspaper title? How does this change over time, place and by politics?\n",
        "\n",
        "**Sub-questions**:\n",
        "- What information do we need? remember `df.columns`)\n",
        "- Is the information all neatly processed and parsed?\n",
        "\n",
        "\n",
        "Run the code cell below to get a negative answer ;-)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cym6BR69Tdiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â get all the unique values in the ESTABLISHED_DATE column\n",
        "df['ESTABLISHED_DATE'].unique()"
      ],
      "metadata": {
        "id": "qpRz0VaJAHm4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait, wait, the 'ESTABLISHED_DATE' column contains **text not numbers** (or dates)."
      ],
      "metadata": {
        "id": "nUmPuV5Yu2nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('value =',df.loc[0,'ESTABLISHED_DATE'])\n",
        "print('value type =',type(df.loc[0,'ESTABLISHED_DATE']))"
      ],
      "metadata": {
        "id": "hFiBniyquOQe"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â get the value counts and select the top ten\n",
        "df['ESTABLISHED_DATE'].value_counts()[:10]"
      ],
      "metadata": {
        "id": "etzyoZwnYqdF"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Searching with regular expressions\n",
        "\n",
        "What to do? How can we convert these messy data to something we can work with?\n",
        "\n",
        "We can extract the year using regular expressions.\n",
        "This is a technique to create complex queries. We define a pattern that we want to find in our text data. In this case, we want to find all the years between 1700-1999.\n",
        "\n",
        "Therefore, we look for numbers consisting of four digits:\n",
        "- starting with 1\n",
        "- followed by a 7,8 or 9\n",
        "- and finishing with any combination of two digits"
      ],
      "metadata": {
        "id": "XlxweMd0FlWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â import the regular expression library\n",
        "import re\n",
        "#Â create the year matching pattern\n",
        "year_pattern = re.compile(r'\\b1[789][0-9]{2}\\b')"
      ],
      "metadata": {
        "id": "g3qfaX6_YnDX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the regular expression pattern on an example string\n",
        "- Question 1: change the `test_string` below and test it yourself;\n",
        "- Question 2: can/should you change the regular expression?"
      ],
      "metadata": {
        "id": "e0jPobnDFeSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â create a string to test the regex\n",
        "test_string = '1960 1543 0323 1789 187e 18982 1892'\n",
        "# apply regex to string\n",
        "year_pattern.findall(test_string)"
      ],
      "metadata": {
        "id": "qD-Hy6kGTbag"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can apply this regex to all the values in the ESTABLISHED_DATE column and extract the year from the date string.\n",
        "\n",
        "However, there are a few problems (which are very common when working with cultural heritage datasets).\n",
        "- some rows do not have a value for these columns -> **missing data**\n",
        "- some rows contain multiple years -> **irregular data**\n",
        "\n",
        "Solutions?\n",
        "- if the cell is **empty**, we take the value in the YEAR column\n",
        "- if the cell contains multiple years, we focus on the first year mentioned\n",
        "\n",
        "Please note: Both of the above steps are **choices** that must be explained and motivated!"
      ],
      "metadata": {
        "id": "xYhxvS5wGULd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the regex to the ESTABLISHED_DATE data column and save result in the ESTABLISHED_YEAR column\n",
        "df['ESTABLISHED_YEAR'] = df['ESTABLISHED_DATE'].apply(lambda x: year_pattern.findall(x))\n",
        "# if no date has been found\n",
        "# - take either the first year\n",
        "# - or the value in the YEAR column\n",
        "#Â convert the numbers to integers\n",
        "df['ESTABLISHED_YEAR'] = df.apply(lambda x: int(x['ESTABLISHED_YEAR'][0]) if len(x['ESTABLISHED_YEAR']) > 0 else x['YEAR'], axis=1)"
      ],
      "metadata": {
        "id": "VvyBh419QwvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â inspect the result of this operation\n",
        "df['ESTABLISHED_YEAR'].unique()"
      ],
      "metadata": {
        "id": "Dm5JKJmeaaso"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compute how old a newspaper is in a given year by subtracting ESTABLISHED_YEAR from YEAR. We save this in a new column with the name **SENIORITY**."
      ],
      "metadata": {
        "id": "hZNlC5kQJLp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â save the difference between YEAR and ESTABLISHED_YEAR in the SENIORITY column\n",
        "df['SENIORITY'] = df.apply(lambda x: int(x['YEAR']) - int(x['ESTABLISHED_YEAR']), axis=1)"
      ],
      "metadata": {
        "id": "l1z7ff0UkaSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â apply mean to get the average age\n",
        "df['SENIORITY'].mean()"
      ],
      "metadata": {
        "id": "ghm06nSjmgos"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# longest run observed during our period\n",
        "df['SENIORITY'].max()"
      ],
      "metadata": {
        "id": "WU4gqszsJm_t"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compute for each year the average SENIORITY of a newspaper titles, and plot the result"
      ],
      "metadata": {
        "id": "y1REpvCeJwqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â groupby by year and compute the mean for the seniority column\n",
        "df.groupby(['YEAR'])['SENIORITY'].mean().plot()"
      ],
      "metadata": {
        "id": "K2FiOTrKp5YT"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make plotting prettier and easier, we can use the seaborn library."
      ],
      "metadata": {
        "id": "QUrI-y29J9Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.lineplot(x='YEAR',y='SENIORITY', data=df)"
      ],
      "metadata": {
        "id": "vS8OhGrHnCVl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's inspect how seniority relates to the political orientation of a newspaper."
      ],
      "metadata": {
        "id": "EQ2i0HKfKHoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â subset data to row containing a specific set of political labels\n",
        "data = df[df['POLITICS'].isin(['liberal', 'conservative','independent','neutral'])]\n",
        "# make a lineplot\n",
        "sns.lineplot(x='YEAR', #Â values for the x-axis\n",
        "             y='SENIORITY', #Â values for the y-axis\n",
        "             hue='POLITICS', #Â split data by values in this cell\n",
        "             hue_order=['conservative', 'liberal','independent','neutral'], # the order of the colors/distinctions\n",
        "             data=data #Â use this data\n",
        "             )"
      ],
      "metadata": {
        "id": "8d_qs2nYkn9Q"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, let's analyse and visualise how the seniority of newspaper titles differs by place. We will need to complete a few more processing steps to visualize this. Again, don't worry if Python is new to you, run the code and look at the outputs!\n",
        "\n",
        "After running the code, download the file it produces ('by_place.csv') and load it into [kepler.gl](https://kepler.gl/)"
      ],
      "metadata": {
        "id": "bgmCcBvMMclG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â remove rows without coordinates\n",
        "df = df[df['PLACE_PUB_COORD'] != '(nan, nan)']\n",
        "# groupy by place name and coordinates\n",
        "by_place = df.groupby(['PLACE_PUB','PLACE_PUB_COORD']).agg({'SENIORITY':'mean', 'ID': 'count'}).reset_index()\n",
        "#Â convert the coordinates from string to a tuple\n",
        "by_place['PLACE_PUB_COORD'] = by_place['PLACE_PUB_COORD'].apply(eval)\n",
        "# save coordinates in different columns\n",
        "by_place['point_latitude'] = by_place.PLACE_PUB_COORD.apply(lambda x: x[0])\n",
        "by_place['point_longitude'] = by_place.PLACE_PUB_COORD.apply(lambda x: x[1])\n",
        "#Â remove the original column\n",
        "by_place.drop('PLACE_PUB_COORD', axis=1, inplace=True)\n",
        "#Â rename ID columns to COUNT\n",
        "by_place.rename(columns={'ID':'COUNT'}, inplace=True)\n",
        "#Â only keep places with more than 10 observation\n",
        "by_place = by_place[by_place.COUNT > 10]\n",
        "#Â save the result in csv file\n",
        "by_place.to_csv('by_place.csv')\n",
        "# now download the file and load it into kepler"
      ],
      "metadata": {
        "id": "uGi3TvGfr1yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "by_place"
      ],
      "metadata": {
        "id": "b573Jf2qsl3r"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case Study 2: Women in the press\n",
        "\n",
        "Let's explore a different question, and study the press directories through a gendered lens.\n",
        "- To what extent are women present?\n",
        "- How does this change over time?"
      ],
      "metadata": {
        "id": "ixL0XOGJQwRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataframe\n",
        "df = pd.read_csv('https://bl.iro.bl.uk/downloads/da65047c-4d62-4ab7-946f-8e61e5f6f331?locale=en', index_col=0)"
      ],
      "metadata": {
        "id": "abjeZcu9jZMu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace not a number nan with empty spaces\n",
        "df.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "Fi6T791BQ6qn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â show three random rows\n",
        "df.sample(3)"
      ],
      "metadata": {
        "id": "Iz87jbhdQ0OF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the values in the PERSONS columns\n",
        "df['PERSONS'].unique()"
      ],
      "metadata": {
        "id": "1bZdRpRXQU3A"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â how many different names are there?\n",
        "len(df['PERSONS'].unique())"
      ],
      "metadata": {
        "id": "amhpprDMzXrA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the most frequent names\n",
        "#Â does it contain women?\n",
        "df['PERSONS'].value_counts()[:5]"
      ],
      "metadata": {
        "id": "ZkV995_ezgJY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Processing names"
      ],
      "metadata": {
        "id": "2t4Vmj-b0g04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the misses (i.e. PERSONS starting with miss)\n",
        "[p for p in df['PERSONS'].unique() if p.lower().startswith('miss')]"
      ],
      "metadata": {
        "id": "f1EUD6A1ROaB"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â split the PERSONS entry by <SEP> and then by white space\n",
        "persons = [i.split() for p in df['PERSONS'].unique() for i in p.split('<SEP>')]"
      ],
      "metadata": {
        "id": "Syk7y1oeRjrQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first five persons\n",
        "persons[:5]"
      ],
      "metadata": {
        "id": "xEJk2_u-RlEA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_person = persons[0]\n",
        "print(first_person)\n",
        "first_name = first_person[0]\n",
        "print(first_name)"
      ],
      "metadata": {
        "id": "jyATLWlX0tcy"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to process the names we\n",
        "#Â - get the first element of the split names\n",
        "#Â - get the lowercased version of the first name\n",
        "#Â - strip any white spaces around the lowercased first name\n",
        "first_names_unique = set([p[0].lower().strip() for p in persons if p])\n",
        "# this reduces the number of names a lot!\n",
        "len(first_names_unique)"
      ],
      "metadata": {
        "id": "k9HKXigDSAc1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first_names_unique"
      ],
      "metadata": {
        "id": "hvF9UlYCSJg4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â I went through the first_names_unique manually and selected\n",
        "#Â names and titles that might refer to women...\n",
        "# then I constructed a regex pattern that will match any name/title\n",
        "female_first_name = ['sarah', 'mary', 'rebecca', 'mrs',  'miss', 'mary', 'maryanne', 'margaret',  'marie', 'louisa', 'honoria',\n",
        "'helen', 'hannah', 'florence', 'evelyn', 'esther', 'ellizabeth', 'elizabeth', 'eliza', 'dora', 'catherine',\n",
        "'annie', 'anne', 'anna', 'ann', 'alice', 'alicia']\n",
        "regex_pattern = '|'.join([fr\"\\b{n}\\b\" for n in female_first_name])\n",
        "print(regex_pattern)"
      ],
      "metadata": {
        "id": "oVL-qTm9XYJ_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we apply the regex pattern to the PERSONS column\n",
        "# for rows with a female name we have it return True, otherwise False\n",
        "# we make it look a bit fancy using a tqdm progress bar\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "pattern = re.compile(regex_pattern)\n",
        "df['has_female_name'] = df['PERSONS'].progress_apply(lambda x: bool(pattern.search(x.lower())))"
      ],
      "metadata": {
        "id": "KvPhHltsaJaT"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â the number of rows with female names\n",
        "df['has_female_name'].sum()"
      ],
      "metadata": {
        "id": "lHtEWLmraqN4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â the percentage of rows with female names\n",
        "round((df['has_female_name'].sum() / len(df))*100,2)"
      ],
      "metadata": {
        "id": "yA-NUOG-2A6o"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â we can zoom in on these rows\n",
        "df[df['has_female_name'] == True]"
      ],
      "metadata": {
        "id": "-3STC2v_agpr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zoom in on the actual text to get more information\n",
        "#Â on the role of women in the press\n",
        "# change the idx to a number smaller dan 779\n",
        "idx = 1\n",
        "df.loc[df['has_female_name'] == True].iloc[idx]['TEXT']"
      ],
      "metadata": {
        "id": "8bhC1k5S2ZUi"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â what are the titles\n",
        "df[df['has_female_name'] == True]['TITLE'].unique()"
      ],
      "metadata": {
        "id": "LjeyGW0BbEdI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â what is the political leaning of these newspapers?\n",
        "df[df['has_female_name'] == True]['POLITICS'].value_counts(normalize=True)[:5]"
      ],
      "metadata": {
        "id": "jbmn8wZUavs7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how does this compare the newspaper landscape?\n",
        "df['POLITICS'].value_counts(normalize=True)[:5]"
      ],
      "metadata": {
        "id": "mib3d6f1ajiB"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â what about changes over time?\n",
        "df[df['has_female_name'] == True].groupby(['YEAR']).size().plot()"
      ],
      "metadata": {
        "id": "8oNwkiiwa5wM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['YEAR'])['PERSONS'].nunique().plot()\n",
        "df.groupby(['YEAR'])['ORGANIZATIONS'].nunique().plot()"
      ],
      "metadata": {
        "id": "JGbCEmTdbeRa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case Study 3: Your Turn!\n",
        "\n",
        "What else would you like to find out?"
      ],
      "metadata": {
        "id": "KmHkWVgJt7gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's start coding"
      ],
      "metadata": {
        "id": "yvf3E_POuHH3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![bye](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExbmFzOHBqaTBiYXh0bGczZ2t3a3VtanRrMWNmZ2owcTVnNGtxMXp3NSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/Z5PxhW6BlWJjCkoPIQ/giphy.gif)"
      ],
      "metadata": {
        "id": "RamsYHNn3aFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fin."
      ],
      "metadata": {
        "id": "-z_QjLW-cYwY"
      }
    }
  ]
}